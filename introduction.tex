\documentclass[main.tex]{subfiles}

\begin{document}
\listoftodos

\begin{itemize}
\item Approximations
  \begin{itemize}
  \item Theoretical results from Bertsekas, do they fit with these methods?
  \end{itemize}
\item Model miss-specification
  \begin{itemize}
  %\item Compare lookahead with multiple scenarios when we have mean miss-specification?
  \item (Shall we argue for Bellman robustness as with parabolic equations?)
  \end{itemize}
\item Conclusion
  \begin{itemize}
  \item Approximations used in industry. Understanding how well they
    perform is important
  \item Forward: more products. Time dependence. Constraints
  \end{itemize}
\end{itemize}


\section{Introduction}
The process of pricing products in order to control demand and
maximize revenues has been undertaken for centuries. In recent
decades, data- and model-driven approaches have become increasingly
popular in order to advise on and automate the process for companies.
There are several success stories from early adopters, for example in
the airline industry. American Airlines estimated in 1992 that
the introduction of yield management software had, over the preceding
three years, contributed \$500 of additional revenue per year,
and would continue to do so in the future \citep{smith1992yield}.
In an example from Chilean retail, \citet{bitran1998coordinating}
report an expected improvement of 7\%-16\% by implementing
model-driven strategies.
For retailers with billions of pounds in revenues, small
improvements to their revenue-management processes is worth millions
of pounds.
Unsold items add up to thousands of tonnes of waste per year, so
improving the control of demand for products is advantageous
for both retailers and the environment.

We are interested in strategies to dynamically set the prices of products, and
formulate the problem as a stochastic optimal control problem.
Product stock levels ${(S)}_t$ are controlled by a pricing process
${(\alpha)}_t$, and evolve according to a dynamic system with random disturbances
${(W)}_t$:
\begin{equation}
S_{t+1}=f_{t+1}(S_t,\alpha_t,W_{t+1})
\end{equation}
The goal is to find $\alpha$ which maximises the revenues $U_t$
given time horizon $T$, and
minimises the costs $\overline{U}$ of unsold stock:
\begin{equation}
  \max_{\alpha}\mathbb E_W\left[ \sum_{t=0}^TU_t(S_t,\alpha_t,W_{t+1})
  - \overline{U}(S_T)\right]
\end{equation}
The solution to this problem can be found by solving the associated
Bellman equation. In practical applications, it is almost always
intractable to solve the control problem to optimality.
Thus, algorithms based on approximations and heuristics are employed.
There are several proposed approximations in the
literature, although most of the domain knowledge is kept within
respective commercial actors.
Many of these algorithms are justified on practical grounds
\citep{aviv2012dynamic}, or
from asymptotic results \citep{gallego1994optimal}.
In this paper, we will consider four approximations known as
lookahead policies,
and evaluate their performance on a one-product system.
We find that the optimal policy is more robust to
miss-specification of the model uncertainty in the system.
Hence, the use of approximations puts more pressure on the
demand forecasting process.

The paper is organised as follows:
In \Cref{sec:bellman_optimal_control} we formulate the
pricing problem mathematically, and describe an algorithm to solve the
problem via the associated Bellman equation. We also give an example
of a problem with one product, and present the optimal pricing rules.
In practical pricing problems, suboptimal approximations are used, as it is intractable to
solve the problem optimally. We discuss a class of suboptimal
algorithms called lookahead policies in
\Cref{sec:suboptimal_approximations}, and compare their performance to
the optimal policy. As the dynamical system is stochastic, the
suboptimal policies may sometimes perform better than the optimal
one. We find that our example, this is indeed true more than half of
the time.
In \Cref{sec:markdown_miss_specification} we consider the issue of
model uncertainty, where the estimation of the random system
disturbance is incorrect. The experiments in that section suggests
that the suboptimal policies are less robust to model uncertainty
than the optimal policy. Hence, the reduction in the cost
of calculating the optimal policies must partially be paid for
by improving the model estimation process.
Finally, we conclude and mention further work in \Cref{sec:conclusion}.

\biblio
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
