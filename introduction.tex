\documentclass[main.tex]{subfiles}

\begin{document}
\listoftodos

\section{Introduction}
The process of pricing products in order to control demand and
maximize revenues has been undertaken for centuries. In recent
decades, data- and model-driven approaches have become increasingly
popular in order to advise on and automate the process for companies.
There are several success stories from early adopters, for example in
the airline industry.
American Airlines estimated in 1992 that the introduction of revenue
management software had, over the preceding three
years, contributed \$500 million of additional revenue per year,
and would continue to do so in the future~\cite{smith1992yield}.
In an example from Chilean retail, the authors of~\cite{bitran1998coordinating}
report an expected revenue improvement of 7\%-16\% from implementing
model-driven strategies.
For retailers with billions of pounds in revenues, small
improvements to their revenue-management processes can be worth millions
of pounds.
In addition unsold items add up to thousands of tonnes of waste per year, so
improving the control of demand for products is advantageous
for both retailers and the environment.

We are interested in strategies to  set the prices of
products dynamically, and thus
formulate the problem in a stochastic optimal control framework.
Let $t$ denote equally spaced, discrete time points in $\{0,1,\dots,T\}$.
Product stock levels $S={(S_t)}_{t=0}^T$ are controlled by a pricing process
$\alpha={(\alpha_t)}_{t=0}^{T-1}$, and evolve according to a transition function $f$ with random disturbance
$W={(W_t)}_{t=1}^T$:
\begin{equation}
  S_{t+1}=f(t,S_t,\alpha_t,W_{t+1}).
\end{equation}
The goal is to find an $\alpha$ which maximises the expected revenues $U_t$ over a
given time horizon $T$, and
minimises the expected cost $\overline{U}$ of unsold stock:
\begin{equation}
  \max_{\alpha}\mathbb E_W\left[ \sum_{t=0}^TU_t(S_t,\alpha_t,W_{t+1})
    - \overline{U}(S_T)\right].
\end{equation}
We use the subscript on $\mathbb E_W$ to emphasise that the
expectation is taken with respect to the random variables $W_t$.
The solution to this problem can be found by solving the associated
Bellman equation.

In practical applications in retail and other domains, it is almost always
intractable to solve the control problem to optimality~\cite{farmer2017uncertainty}.
The modelling of a real system and decision process can become very
complicated, and  we must  create a very
large state space in order to make use of the Bellman equation.
We often have to take into account unobservable
state variables, such as estimated parameters, and constraints
that may depend on history. Decision-makers in business may change their mind
about the objective over the course of the decision period, which should
be incorporated in the modelling as parameters with corresponding, estimated
probability distributions.
From a software implementation perspective, writing code that can
solve the Bellman equation efficiently can be much more complicated
than other methods.
Finally, the dimensions of the state, policy and exogenous
information spaces, can quickly make a numerical solution to the Bellman
equation intractable. An explosion of dimensions can happen very
quickly, even for one-product problems.
In~\cite{bertsimas2001dynamic}, the authors model a simple
one-product demand function with uncertainty in the function
parameters, and present an eight-dimensional dynamic programming
solution to the problem.
Much of the focus in the research community has therefore been on
developing tractable algorithms with comparable average performance to the
optimal policies, see for
example~\cite{powell2011approximate} or~\cite{bertsekas2012dynamic}.
One can either create explicit policy functions off-line, at the
start of the decision process, or implicitly through an automated
search for the best policy on-line for each decision point.
An advantage of the pre-calculated, explicit policy functions
is the speed at which we can make our decisions in the
future. In the classical pricing problems, the dynamics of the
underlying system do not require instant pricing decisions. Thus,
suboptimal decision rules that are created as they are needed, are often used
instead~\cite{talluri2006theory}. Estimation of the system and optimisation of prices are
normally separated, and constraints are more easily updated at each
decision point.

There are several proposed approximations in the
literature, although for revenue management applications, much of the domain knowledge is kept within
respective commercial organisations~\cite[Ch.~9]{talluri2006theory}.
Many of the suboptimal pricing algorithms are justified on practical
grounds~\cite{aviv2012dynamic}, or
from asymptotic results~\cite{gallego1994optimal}.
The aim of this article is to highlight the implications suboptimal policy
choices have on the distribution of the relevant objective, and not
only marginalised quantities such as the expected value.
In particular, we consider a one-product pricing problem and
investigate the optimal Bellman policy, an often-used suboptimal
policy known as the \emph{Certainty Equivalent Control} (CEC)
policy, and a compromise between optimality and practicality known as the
\emph{Open-Loop Feedback Control} policy.
Rather surprisingly, we find that, more than half the
time, using the suboptimal CEC policy
leads to a higher profit than using the Bellman policy. Of course, the
Bellman policy performs better on average, but
this is due to the CEC policy generating a larger, lower tail on the
distribution of profits than the Bellman policy.
Heuristically, one can say that the CEC policy has a higher risk
associated to it. We wish to emphasise that this indicates that a
choice of approximate control policy is implicitly a statement of
risk attitude. Thus, it should be addressed at the same level as a
description of a decision-maker's risk attitude as expressed with
utility functions or risk measures.

The article is organised as follows:
In \Cref{sec:bellman_optimal_control} we formulate the
pricing problem mathematically, and describe an algorithm to solve the
problem via the associated Bellman equation. We also give an example
of a problem with one product, and present the optimal pricing rules.
A discussion of the CEC and OLFC policies follows in
\Cref{sec:suboptimal_approximations}, where we compare its
performance to that of
the optimal policy.
Finally, we conclude and propose further work in \Cref{sec:conclusion}.

\biblio
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
