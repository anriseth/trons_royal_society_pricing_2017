\documentclass[main.tex]{subfiles}

% This code shows which label has been changed when latex complains
% \makeatletter
% \def\@testdef #1#2#3{%
% \def\reserved@a{#3}\expandafter \ifx \csname #1@#2\endcsname
% \reserved@a  \else
% \typeout{^^Jlabel #2 changed:^^J%
% \meaning\reserved@a^^J%
% \expandafter\meaning\csname #1@#2\endcsname^^J}%
% \@tempswatrue \fi}
% \makeatother

\begin{document}

\listoftodos

\section{The optimal control problem}\label{sec:bellman_optimal_control}
The overarching goal in the article is to consider solutions to a retail
pricing problem.
Given some initial amount of stock of a product and a future
termination time,
the pricing problem is to
dynamically set the price
of the product in order to maximise revenue and minimise the cost of
unsold stock at the termination time.
In this section, we define the optimal control pricing problem,
describe the optimality conditions given by the Bellman equation and
solve it numerically for an example system.

Consider a system over discrete, equispaced time points
$t=0,1,\dots,T$, with state
$S_t$ and policy process $\alpha_t$ that takes values in a closed
interval $A=[a_{\mathrm{min}},a_{\mathrm{max}}]\subset\mathbb R_+$.\footnote{
  In practice, policy values may have additional constraints that depend
  on the current state,
  in which case we say that $\alpha_t$ must take values
  in a set $A(S_t)$.
}
The state $S_t$ is the stock of a product at time $t$, and
$\alpha_t$ the price for the product in the time period from $t$ to
$t+1$. We model the amount of product sold over each time period according
to a forecast demand
function $q:A\to\mathbb R_+$, which is bounded, continuous and decreasing.
Exogenous influences on demand are considered as randomness in the
system, and are
modelled in a multiplicative fashion by a stochastic process
$(W_t)$ taking non-negative values. See, for example,
\citet[Ch.~7]{talluri2006theory} for a discussion of
popular demand models and the modelling of uncertainty.

For a given pricing process $\alpha$, the
system evolves from some initial state $S_0>0$, according to the
recursion
\begin{equation}\label{eq:stock_dynamics}
  S_{t+1}^\alpha=S_t^\alpha-\min(S_t^\alpha,q(\alpha_t)W_{t+1}),\qquad t=0,\dots,T-1.
\end{equation}
The function $Q(s,a,w)=\min(s,q(a)w)$ denotes the unit sales over a
period at price $a$,
starting with stock $s$, and with exogenous influences
characterised by $w$.

The revenue accrued over period $t\to t+1$ is $\alpha_tQ(S_t^\alpha,\alpha_t,W_{t+1})$.
The cost of remaining stock at time $T$ is modelled by a cost per unit
stock $C\geq 0$.\footnote{In some situations, unsold items at time $T$
  may be sold at some ``salvage price'', in which case we could allow
  $C<0$.}
Let $\mathcal A$ denote the set of feasible processes that take values
in $A$.
Define the value of having stock $s$ at time $t\leq T$
by the \emph{value function}
\begin{align}\label{eq:value_function_def}
  v(t,s)&=\max_{\alpha\in\mathcal A} J(t,s,\alpha),\quad\text{where}\\
  J(t,s,\alpha)&=
                 \mathbb E_{W}\left[ \sum_{\tau=t}^{T-1}
                 \alpha_\tau Q(S_\tau^\alpha,\alpha_\tau,W_{\tau+1})
                 - CS_T^\alpha \mid S_t^\alpha = s
                 \right].
                 \label{eq:value_function_def2}
\end{align}
This leads us to the following mathematical formulation of the pricing
problem:
\begin{mydef}
  Given an initial stock $S_0>0$ and a cost per unit unsold stock $C\geq
  0$, the \emph{pricing problem} is to find $\alpha\in\mathcal A$ such that
  \begin{equation}
    J(0,S_0,\alpha) = v(0,S_0).
  \end{equation}
\end{mydef}
We choose to maximise the expected profit over the period, which
assumes a risk-neutral decision-maker. However, it is still important
to understand the distribution of profits for a given pricing policy
$\alpha$. Therefore, we simulate the distribution when
we investigate the performance of algorithms in
\Cref{sec:suboptimal_approximations,sec:markdown_miss_specification}.
If we assume that the random variables $W_t$ are independent, this
stochastic optimal control problem can be solved by
considering the optimality conditions that arise from the Dynamic
Programming principle, also known as the Bellman equation.

\subsection{Non-dimensionalisation of the system}
We will now consider a non-dimensionalised
representation of the system.
The unit of time is already scaled such that
the difference between two time points is $1$.
The units of stock will be  scaled with
respect to
the initial stock $S_0$, and units of money will be scaled with respect to
the upper bound on
price, $a_{\mathrm{max}}$.
Let the corresponding dimensionless quantities be defined with hats.
Then we set
\begin{align}
  \hat s
  &= \frac{s}{S_0},
  &\hat a
  &=\frac{a}{a_{\mathrm{max}}},
  &\hat C&=\frac{C}{a_{\mathrm{max}}},
  &\hat t &= t,
  &\hat W_{\hat t}&=W_{t}.
\end{align}
The dimensionless functions $\hat q(\hat a)$ and $\hat Q(\hat s,\hat
a, \hat w)$,
for forecasted demand
and realised sales respectively, should then be defined as
\begin{align}
  \hat q(\hat a)&= \frac{q(\hat a\cdot a_{\max})}{S_0},
  &\hat Q(\hat s,\hat a, \hat w)&= \min(\hat s, \hat q(\hat a)\hat w).
\end{align}
The collection of pricing policies $\hat{\mathcal A}$ contains all
the processes $\alpha_t/a_{\mathrm{max}}$, where $\alpha\in \mathcal
A$. Now we can define the dimensionless value function
\begin{align}\label{eq:value_function_def_nondim}
  \hat v(\hat t,\hat s)&=\max_{\hat \alpha\in\hat{\mathcal A}}
                    \hat J(\hat t,\hat s,\hat \alpha),\quad\text{where}\\
  \hat J(\hat t,\hat s,\hat \alpha)&=
                 \mathbb E_{\hat W}\left[ \sum_{\tau=\hat t}^{\hat T-1}
                 \hat \alpha_\tau\hat Q(\hat
                                     {S_\tau^\alpha},\hat{\alpha_\tau},\hat
                                     W_{\tau+1})
                 - \hat C \hat{S}_{\hat{T}}^\alpha \mid \hat{S}_{\hat{t}}^\alpha =
                                \hat s
                 \right].
                 \label{eq:value_function_def_nondim2}
\end{align}
Finally, the dimensionless optimal control problem
is to find $\hat \alpha^*\in\hat{\mathcal A}$, such that
$\hat J(0,1,\hat \alpha^*)=\hat v(0,1)$.
For the remainder of this article, we work with the
non-dimensionalised system, and drop the hats from the
dimensionless quantities.

\subsection{The Bellman equation}
We assume the optimal policy $\alpha\in\mathcal A$ is Markovian,\todo{
  do I need to justify that the optimal policy is Markovian?}
meaning that
there exists a function $a(t,s)$ such that for each possible outcome
$\omega$, the process is given by
$\alpha_t(\omega) =
a(t,S_t^\alpha(\omega))$.
Then,
an approach to finding the value function above is to use the Dynamic
Programming principle, which states that $v$ can be defined
recursively by
\begin{equation}\label{eq:dynamic_programming_discrete}
  v(t,s)=\max_{a\in A}\mathbb E_{W}\left[
          aQ(s,a,W_{t+1})
          +v(t+1,s-Q(s,a,W_{t+1}))\right].
\end{equation}
Thus, the value function is the solution to the backwards-in-time
recursive relation~\eqref{eq:dynamic_programming_discrete} with
terminal value $v(T,s)=-Cs$, and the optimal policy
function $a(t,s)$ is given by the argmax for each $(t,s)$.
The recursion is called the \emph{Bellman equation}, and a discussion
of its validity can be found, for example, in
\citet{bertsekas2005dynamic}.
Analytical solutions to Bellman equations are only available in very
simplified cases, and thus numerical approaches are normally needed to
solve the equation.

We implement the following algorithm to solve the optimal control
problem, using the Bellman equation:\todo{Decorate with some algorithm environment?}
\begin{enumerate}
\item Create a grid of equispaced points $0=s_1<s_2<\cdots<s_K=S_0$, and arrays $v^K\in\mathbb R^{K\times(T+1)}$,
  $\alpha^K\in\mathbb R^{K\times T}$.
\item Set $Iv^K(s)=-Cs$.
\item Set $v^K[i,T]=Iv^K(s_i)$ for $i=1,\dots, K$.
\item For $t = T-1,\dots,0$:
  \begin{enumerate}
  \item Set $\displaystyle v^K[i,t]=\max_{a\in A}\mathbb E_{W_{t+1}}\left[ aQ(s_i,a,W_{t+1})
      +Iv^K(s_i-Q(s,a,W_{t+1}))\right]$\\ for $i=1,\dots,K$.
  \item Set $\alpha^K[i,t]$ to the maximiser above.
  \item Set $Iv^K(s) = \mathrm{Interpolate}(s, {(s_i)}_i,{(v^K[i,t])}_i)$.
  \end{enumerate}
\item Return $v^K,\alpha^K$.
\end{enumerate}
The expectation above is approximated using Monte-Carlo simulation, and
we chose to use a linear interpolation for $Iv^K(s)$.

\subsection{Example system}\label{sec:bellman_example_markdown}
In the numerical experiments, we choose to look at the demand function
defined on $A=[0,1]$,
given by
\begin{equation}
  q(a)={\textstyle\frac{1}{3}}e^{2-3a}.
\end{equation}
We assume the exogenous disturbance process is a sequence of
shifted, independent and identically Beta-distributed random
variables with mean $1$ and variance
$\gamma^2$. That is, we define $W_t\sim \frac{1}{2}+X$, where
$X\sim \mathrm{Beta}(\mu,\nu)$,\footnote{
  A $\mathrm{Beta}(\mu,\nu)$ random variable has probability density
  function on $[0,1]$, given by
  $p(x)=\frac{x^{\mu-1}{(1-x)}^{\nu-1}}{B(\mu,\nu)}$.
  The function $B(\mu,\nu)$ acts as a normalising factor.
}
and $\mu=\nu=\frac{1}{8\gamma^2}-\frac{1}{2}$.

Set $\gamma = 5\times 10^{-2}$, $C=1$ and $T=3$.
The solution to the Bellman equation, and the corresponding optimal
pricing policy is shown in \Cref{fig:markdown_bellman}.
\begin{figure}[htbp]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \begin{tikzpicture}[scale=0.8]
      \begin{axis}[
        xlabel={$s$},
        ylabel={$v(t,s)$},
        title={Value function},
        legend cell align=left,
        legend pos=north west
        ]
        \addplot+[mark=none] table[x index = 0,y index = 1,col sep=comma]
        {./data/markdown_bellman_det_val_policy.csv};
        \addlegendentry{$t=0$};
        \addplot+[mark=none] table[x index = 0,y index = 2,col sep=comma]
        {./data/markdown_bellman_det_val_policy.csv};
        \addlegendentry{$t=1$};
        \addplot+[mark=none] table[x index = 0,y index = 3,col sep=comma]
        {./data/markdown_bellman_det_val_policy.csv};
        \addlegendentry{$t=2$};
      \end{axis}
    \end{tikzpicture}
    % \includegraphics[width=\textwidth]{./img/markdown_value_bellman}
  \end{subfigure}%
  \begin{subfigure}[b]{0.5\textwidth}
    \begin{tikzpicture}[scale=0.8]
      \begin{axis}[
        xlabel={$s$},
        ylabel={$a(t,s)$},
        title={Policy function},
        legend cell align=left,
        ]
        \addplot+[mark=none] table[x index = 0,y index = 5,col sep=comma]
        {./data/markdown_bellman_det_val_policy.csv};
        \addlegendentry{$t=0$};
        \addplot+[mark=none] table[x index = 0,y index = 6,col sep=comma]
        {./data/markdown_bellman_det_val_policy.csv};
        \addlegendentry{$t=1$};
        \addplot+[mark=none] table[x index = 0,y index = 7,col sep=comma]
        {./data/markdown_bellman_det_val_policy.csv};
        \addlegendentry{$t=2$};
      \end{axis}
    \end{tikzpicture}
    % \includegraphics[width=\textwidth]{./img/markdown_controls_bellman}
  \end{subfigure}
  \caption{The value function and corresponding
    optimal control function for the pricing problem.
    The regions where the value function moves from a linear to a
    non-linear regime
    corresponds to when the pricing policy hits the upper bound 1.
  }\label{fig:markdown_bellman}
\end{figure}
Let us now investigate the behaviour of the optimal pricing policy
$\alpha$ and
the outcome of following this policy.
Define a random variable $P^\alpha$, which for each realisation
represents the total profit,
\begin{equation}
  P^\alpha = \sum_{t=0}^{T-1}\alpha_tQ(S_t^\alpha,\alpha_t,W_{t+1}) - CS_T^\alpha.
\end{equation}
By sampling from the stochastic process $W=(W_1,\dots,W_T)$, we can
estimate the random variables $\alpha_t$ and $P^\alpha$.
The plots in \Cref{fig:bellman_simulation} show the results of
simulating the system $1000$ times.\footnote{
  Preliminary investigations indicated that $1000$
  simulations is enough to get a good representation of
  the distributions in this article.
}

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.5\textwidth}
    \begin{tikzpicture}[scale=0.8]
      \begin{axis}[
        ylabel={Price},
        xlabel={\phantom{$P^\alpha$}},% \phantom: to align the two figures
        title={$\alpha_t$, simulated values},
        boxplot/draw direction=y,
        xtick={1,2,3},
        xticklabels={$t=0$, $t=1$, $t=2$},
        % ymin=0.6,ymax=0.75
        ]
        \addplot+[boxplot] table[y index=0,col sep=comma]
        {./data/markdown_bellman_det_policies.csv};
        \addplot+[boxplot = {whisker range = 2}] table[y index=1,col sep=comma]
        {./data/markdown_bellman_det_policies.csv};
        \addplot+[boxplot = {whisker range = 2}] table[y index=2,col sep=comma]
        {./data/markdown_bellman_det_policies.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}%
  \begin{subfigure}[t]{0.5\textwidth}
    \begin{tikzpicture}[scale=0.8]
      \begin{axis}[
        xlabel=$P^{\alpha}$,
        ylabel=Count,
        title={Realised profit},
        legend cell align=left
        ]
        \addplot[blue,hist={data=x,bins=40}] table [y index = 0, col
        sep=comma]
        {./data/markdown_bellman_det_vals.csv};
      \end{axis}
    \end{tikzpicture}
  \end{subfigure}%
  % \begin{subfigure}[b]{0.5\textwidth}
  %   \begin{tikzpicture}[scale=0.8]
  %     \begin{axis}[
  %       title={$\alpha_t^C$, simulated values},
  %       boxplot/draw direction=y,
  %       xtick={1,2,3},
  %       xticklabels={$t=0$, $t=1$, $t=2$},
  %       ymin=0.6,ymax=0.75
  %       ]
  %       \addplot+[boxplot] table[y index=3,col sep=comma]
  %       {./data/markdown_bellman_det_policies.csv};
  %       \addplot+[boxplot] table[y index=4,col sep=comma]
  %       {./data/markdown_bellman_det_policies.csv};
  %       \addplot+[boxplot] table[y index=5,col sep=comma]
  %       {./data/markdown_bellman_det_policies.csv};
  %     \end{axis}
  %   \end{tikzpicture}
  % \end{subfigure}%
  \caption{Simulations of the pricing system, started at $S_0=1$ % TODO: subscript _0 causes issues with label re-run warnings
    and
    controlled by the optimal policy $\alpha$ shown in
    \Cref{fig:markdown_bellman}.
    The left figure is a box plot
    that shows the median, the quartiles and the extremal prices observed
    in the simulations.
    As we see, the variance of the prices increases
    in time, reflecting the wider range of realised remaining stock at these times.
    The right figure is a histogram of the profits over
    the pricing period.
  }\label{fig:bellman_simulation}
\end{figure}

\todo[inline]{Do we need some sort of ``concluding'' remarks here?}

\biblio
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
