\documentclass[main.tex]{subfiles}

\begin{document}

\abstract{
  In this paper, we investigate  Approximate Dynamic Programming (ADP)
  algorithms to a pricing problem for retailers.
  The pricing problem is formulated as a stochastic optimal
  control problem, where the optimal policy can be found by solving
  the associated Bellman equation.
  For realistic retail applications, modelling the problem and solving
  the to optimality becomes impractical and intractable.
  Thus practitioners make simplifying assumptions, but thorough investigations
  of their relative performance is lacking.
  A challenge in ADP is to better understand
  such trade-offs, which this paper contributes to.
  We simulate the performance on a one-product system, and find that
  certain situations, the popular certainty equivalent control policy
  can perform better than the optimal, expected value maximising policy more than
  \emph{half of the time}.
  However, this algorithm is less robust to model uncertainty, which
  requires the retailer to spend more resources on system estimation.
}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
