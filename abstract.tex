\documentclass[main.tex]{subfiles}

\begin{document}

\abstract{
  In this paper, we investigate  Approximate Dynamic Programming (ADP)
  algorithms to a pricing problem for retailers.
  The pricing problem is formulated as a stochastic optimal
  control problem, where the optimal policy can be found by solving
  the associated Bellman equation.
  For realistic retail applications, modelling the problem and solving
  it to optimality becomes impractical and intractable.
  Thus practitioners make simplifying assumptions, but thorough investigations
  of their relative performance is lacking.
  A challenge in ADP is to better understand
  such trade-offs, which this paper contributes to.
  We simulate the performance of a family of algorithms on a
  one-product system, and find that in
  certain situations, the popular Certainty Equivalent Control policy
  can perform better than the optimal, expected value maximising policy more than
  \emph{half of the time}.
  However, this algorithm is less robust to model uncertainty, and thus
  requires that the retailer spends more resources on system estimation.
}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
